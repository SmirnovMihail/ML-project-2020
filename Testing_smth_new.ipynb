{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, cross_val_score, GroupKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    \n",
    "    titles_df = pd.read_csv('./data/docs_titles.tsv/docs_titles.tsv', sep='\\t')\n",
    "    docs_id_test = pd.read_csv('./data/test_groups.csv', sep=',')\n",
    "    docs_id_train = pd.read_csv('./data/train_groups.csv', sep=',')\n",
    "\n",
    "    info = pd.concat([docs_id_train, docs_id_test])\n",
    "    info.reset_index(drop=True)\n",
    "\n",
    "    titles = pd.merge(titles_df, info[['group_id', 'doc_id', 'target']], on='doc_id', how='inner')\n",
    "    titles['title'] += ' '\n",
    "    titles['title'].fillna(' ', inplace=True)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles_extraction():\n",
    "    \n",
    "    titles = get_df();\n",
    "\n",
    "    titles = titles[['title', 'group_id']].groupby('group_id').sum()['title']\n",
    "\n",
    "    titles = titles.apply(lambda x: cleaner(x))\n",
    "    titles = titles.values\n",
    "\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(titles, group_num, bad_words):\n",
    "    titles = titles.lower()\n",
    "    titles = re.sub(r'\\W', '  ', titles)\n",
    "    \n",
    "    for i in bad_words[group_num]:\n",
    "            titles = titles.replace(i, ' ')\n",
    "    titles = re.sub(r'\\s+', ' ', titles)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Porter:\n",
    "    PERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "    REFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "    ADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "    PARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "    VERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "    NOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "    RVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "    DERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "    DER = re.compile(u\"ость?$\")\n",
    "    SUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "    I = re.compile(u\"и$\")\n",
    "    P = re.compile(u\"ь$\")\n",
    "    NN = re.compile(u\"нн$\")\n",
    "\n",
    "    def stem(string):\n",
    "        \n",
    "        changed = ''\n",
    "        \n",
    "        string = string.lower()\n",
    "\n",
    "        for word in string.split():\n",
    "            if not word.isdigit():\n",
    "                word = word.replace(u'ё', u'е')\n",
    "                m = re.match(Porter.RVRE, word)\n",
    "\n",
    "                if m and m.groups():\n",
    "                    pre = m.group(1)\n",
    "                    rv = m.group(2)\n",
    "                    temp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "                        temp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "                        if temp != rv:\n",
    "                            rv = temp\n",
    "                            rv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "                        else:\n",
    "                            temp = Porter.VERB.sub('', rv, 1)\n",
    "                            if temp == rv:\n",
    "                                rv = Porter.NOUN.sub('', rv, 1)\n",
    "                            else:\n",
    "                                rv = temp\n",
    "                    else:\n",
    "                        rv = temp\n",
    "\n",
    "                    rv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "                    if re.match(Porter.DERIVATIONAL, rv):\n",
    "                        rv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "                    temp = Porter.P.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "                        rv = Porter.NN.sub(u'н', rv, 1)\n",
    "                    else:\n",
    "                        rv = temp\n",
    "                    word = pre+rv\n",
    "\n",
    "            changed += word + ' '\n",
    "\n",
    "        return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28026\n"
     ]
    }
   ],
   "source": [
    "doc_to_title = {}\n",
    "with open('./data/unversal_table.csv') as f:\n",
    "    for num_line, line in enumerate(f):\n",
    "        if num_line == 0:\n",
    "            continue\n",
    "#         print(type(line))\n",
    "        line = line.replace('\\t', ',')\n",
    "        \n",
    "        data = line.strip().split(',')\n",
    "#         print(data)\n",
    "        doc_id = int(data[0])\n",
    "        if len(data) == 1:\n",
    "            title = ''\n",
    "        else:\n",
    "            title = data[1]\n",
    "        doc_to_title[doc_id] = title\n",
    "print (len(doc_to_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('./data/train_groups.csv')\n",
    "# train_data = train_titles\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(train_data)):\n",
    "    new_doc = train_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    target = new_doc['target']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title, target))\n",
    "# traingroups_titledata[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11690, 25) (11690,) (11690,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_train = []\n",
    "X_train = []\n",
    "groups_train = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
    "        y_train.append(target_id)\n",
    "        groups_train.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j, target_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        X_train.append(sorted(all_dist, reverse=True)[0:25]    )\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "groups_train = np.array(groups_train)\n",
    "print (X_train.shape, y_train.shape, groups_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_data = pd.read_csv('./data/test_groups.csv')\n",
    "# test_data = test_titles\n",
    "traingroups_titledata = {}\n",
    "for i in range(len(test_data)):\n",
    "    new_doc = test_data.iloc[i]\n",
    "    doc_group = new_doc['group_id']\n",
    "    doc_id = new_doc['doc_id']\n",
    "    title = doc_to_title[doc_id]\n",
    "    if doc_group not in traingroups_titledata:\n",
    "        traingroups_titledata[doc_group] = []\n",
    "    traingroups_titledata[doc_group].append((doc_id, title))\n",
    "# traingroups_titledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16627, 25) (16627,)\n"
     ]
    }
   ],
   "source": [
    "# y_train = []\n",
    "X_test = []\n",
    "groups_test = []\n",
    "for new_group in traingroups_titledata:\n",
    "    docs = traingroups_titledata[new_group]\n",
    "    for k, (doc_id, title) in enumerate(docs):\n",
    "#         y_train.append(target_id)\n",
    "        groups_test.append(new_group)\n",
    "        all_dist = []\n",
    "        words = set(title.strip().split())\n",
    "        for j in range(0, len(docs)):\n",
    "            if k == j:\n",
    "                continue\n",
    "            doc_id_j, title_j = docs[j]\n",
    "            words_j = set(title_j.strip().split())\n",
    "            all_dist.append(len(words.intersection(words_j)))\n",
    "        X_test.append(sorted(all_dist, reverse=True)[0:25]    )\n",
    "X_test = np.array(X_test)\n",
    "# y_train = np.array(y_train)\n",
    "groups_test = np.array(groups_test)\n",
    "print (X_test.shape, groups_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    \n",
    "    result = []\n",
    "    for elem in x:\n",
    "        if hasattr(elem, \"__iter__\") and not isinstance(elem, str):\n",
    "            result.extend(flatten(elem))\n",
    "        else:\n",
    "            result.append(elem)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_concat(list1, list2):\n",
    "    \n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    \n",
    "    return [[list1[i], list2[j]] for i in range(len1) for j in range(len2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(params):\n",
    "    \n",
    "    list_ = []\n",
    "    for value in params.values():\n",
    "        list_.append(value)\n",
    "\n",
    "    tmp = reduce(lambda x, y: list_concat(x, y), list_)\n",
    "\n",
    "    res = []\n",
    "    for elem in tmp:\n",
    "        param_list = flatten(elem)\n",
    "        param_dict = dict(zip(params.keys(), param_list))\n",
    "        res.append(param_dict)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X_train, train_target, model, params, folds_gen_func, groups_num=10, thresholds=[0.27], **kwargs):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train) \n",
    "    \n",
    "    main_res = []\n",
    "    for param_set in combinations(params):\n",
    "        \n",
    "        print(param_set)        \n",
    "        exact_model = model(**param_set) \n",
    "        \n",
    "        fold_generator = folds_gen_func(groups_num)\n",
    "        \n",
    "        for th in thresholds:\n",
    "    #         th = 0.27\n",
    "            res = []\n",
    "            for train_index, test_index in fold_generator.split(X_train, train_target, **kwargs):\n",
    "\n",
    "                exact_model.fit(scaler.transform(X_train[train_index]), train_target[train_index])\n",
    "\n",
    "                y_pred = [0 if val < th else 1 for val in exact_model.predict_proba(scaler.transform(X_train[test_index]))[:,1]]\n",
    "\n",
    "                score = metrics.f1_score(train_target[test_index],\\\n",
    "                                                y_pred)\n",
    "    #               print('threshold = {}, score = {}'.format(th, score))\n",
    "\n",
    "                res.append(score)\n",
    "        #                                       exact_model.predict(scaler.transform(X_train[test_index]))))\n",
    "\n",
    "\n",
    "            mean = sum(res)/len(res)\n",
    "            print(mean)\n",
    "#             print('threshold = {}, score = {}'.format(th, mean))\n",
    "            main_res.append((mean, param_set, th))\n",
    "    \n",
    "    best = main_res[np.argmax([res[0] for res in main_res])]\n",
    "    print('--------max-------')\n",
    "    print(best)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняет решение\n",
    "\n",
    "def save_submission(y_pred):\n",
    "\n",
    "    data = pd.read_csv('data/test_groups.csv')\n",
    "    print('len data = ', len(data))\n",
    "    data['target'] = y_pred\n",
    "    \n",
    "    data = data.drop(['group_id', 'doc_id'], axis=1)\n",
    "\n",
    "    data.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "    info = np.unique(data['target'], return_counts=True)\n",
    "    \n",
    "    if info[0].shape[0] > 1:\n",
    "        \n",
    "        print('0: {}, 1: {}'.format(info[1][0], info[1][1]))\n",
    "        if info[1][1] > 6000 or info[1][1] < 2500:\n",
    "            print('Your submisson is shit')\n",
    "#         elif info[1][1] > 4500:\n",
    "#             print('Your submisson is probably shit')\n",
    "    else:\n",
    "        print('There are only {} in submission'.format(info[0][0]))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, X_test, train_target, model, scaler=None, **kwargs):\n",
    "    \n",
    "    curr_model = model(**kwargs)\n",
    "    \n",
    "    if scaler is not None:\n",
    "        \n",
    "        your_scaler = scaler()\n",
    "        your_scaler.fit(X_train)\n",
    "        X_train = your_scaler.transform(X_train)\n",
    "        X_test = your_scaler.transform(X_test)\n",
    "        \n",
    "    curr_model.fit(X_train, train_target)\n",
    "#     y_pred = curr_model.predict(X_test)\n",
    "    th = 0.27\n",
    "    y_pred = [0 if val < th else 1 for val in curr_model.predict_proba(X_test)[:,1]]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': [0.07, 0.08],\n",
    "#           'n_estimators': [372, 374]}\n",
    "          'n_estimators': [175, 180, 185, 190, 195, 200]}\n",
    "groups_train = pd.read_csv('data/train_groups.csv')['group_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.07, 'n_estimators': 175}\n",
      "0.675927739183593\n",
      "{'learning_rate': 0.07, 'n_estimators': 180}\n",
      "0.6771843653928997\n",
      "{'learning_rate': 0.07, 'n_estimators': 185}\n",
      "0.6763211582461116\n",
      "{'learning_rate': 0.07, 'n_estimators': 190}\n",
      "0.6773301941599585\n",
      "{'learning_rate': 0.07, 'n_estimators': 195}\n",
      "0.6774711769133916\n",
      "{'learning_rate': 0.07, 'n_estimators': 200}\n",
      "0.6773499260968933\n",
      "{'learning_rate': 0.08, 'n_estimators': 175}\n",
      "0.6757725614146477\n",
      "{'learning_rate': 0.08, 'n_estimators': 180}\n",
      "0.6758920866929061\n",
      "{'learning_rate': 0.08, 'n_estimators': 185}\n",
      "0.6757862965806443\n",
      "{'learning_rate': 0.08, 'n_estimators': 190}\n",
      "0.6748040281293924\n",
      "{'learning_rate': 0.08, 'n_estimators': 195}\n",
      "0.6750727264102429\n",
      "{'learning_rate': 0.08, 'n_estimators': 200}\n",
      "0.6750016495894133\n",
      "--------max-------\n",
      "(0.6774711769133916, {'learning_rate': 0.07, 'n_estimators': 195}, 0.27)\n"
     ]
    }
   ],
   "source": [
    "best = validation(X_train, y_train, GradientBoostingClassifier, params, GroupKFold, groups=groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len data =  16627\n",
      "0: 10613, 1: 6014\n",
      "Your submisson is shit\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_train, X_test, y_train, GradientBoostingClassifier, StandardScaler, **best[1])\n",
    "data = save_submission(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_titles(df):\n",
    "    stemming = Porter\n",
    "    return df['title'].apply(lambda x: stemming.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/core_train.csv')\n",
    "df_test = pd.read_csv('data/core_test.csv')\n",
    "df_train.fillna(' ', inplace=True)\n",
    "df_test.fillna(' ', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = pd.concat([df_train, df_test])\n",
    "# titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15731</td>\n",
       "      <td>ваз зам подшипник ступиц нив зам подшипник сту...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14829</td>\n",
       "      <td>ваз опт соч сравн цен куп потребительск товар ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15764</td>\n",
       "      <td>куп ступиц лад калин трансмисс переходн ступиц...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17669</td>\n",
       "      <td>классик learn center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14852</td>\n",
       "      <td>ступиц нив зам подшипник сво рук ступиц нив ка...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16622</th>\n",
       "      <td>16637</td>\n",
       "      <td>ответ mail полезн куша творог утр есл худ попр...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16623</th>\n",
       "      <td>16759</td>\n",
       "      <td>творог полезн свойств лечен творог женск сайт ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16624</th>\n",
       "      <td>15358</td>\n",
       "      <td>творог полезн опасн свойств творог творог</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16625</th>\n",
       "      <td>17287</td>\n",
       "      <td>ответ mail чем полез творог чем полез творог</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16626</th>\n",
       "      <td>16026</td>\n",
       "      <td>творог польз вред как выбира продукт фитнес зд...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id                                              title\n",
       "0       15731  ваз зам подшипник ступиц нив зам подшипник сту...\n",
       "1       14829  ваз опт соч сравн цен куп потребительск товар ...\n",
       "2       15764  куп ступиц лад калин трансмисс переходн ступиц...\n",
       "3       17669                              классик learn center \n",
       "4       14852  ступиц нив зам подшипник сво рук ступиц нив ка...\n",
       "...       ...                                                ...\n",
       "16622   16637  ответ mail полезн куша творог утр есл худ попр...\n",
       "16623   16759  творог полезн свойств лечен творог женск сайт ...\n",
       "16624   15358         творог полезн опасн свойств творог творог \n",
       "16625   17287      ответ mail чем полез творог чем полез творог \n",
       "16626   16026  творог польз вред как выбира продукт фитнес зд...\n",
       "\n",
       "[28317 rows x 2 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = pd.DataFrame({'doc_id': titles_df['doc_id'] ,\n",
    "                       'title': titles_df['title'] + titles_df['h1']})\n",
    "\n",
    "titles['title'] = stemming_titles(titles)\n",
    "\n",
    "titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.to_csv('./data/unversal_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
