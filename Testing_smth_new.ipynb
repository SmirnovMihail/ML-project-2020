{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from functools import reduce\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_validate, KFold, cross_val_score, GroupKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df():\n",
    "    \n",
    "    titles_df = pd.read_csv('./data/docs_titles.tsv/docs_titles.tsv', sep='\\t')\n",
    "    docs_id_test = pd.read_csv('./data/test_groups.csv', sep=',')\n",
    "    docs_id_train = pd.read_csv('./data/train_groups.csv', sep=',')\n",
    "\n",
    "    info = pd.concat([docs_id_train, docs_id_test])\n",
    "    info.reset_index(drop=True)\n",
    "\n",
    "    titles = pd.merge(titles_df, info[['group_id', 'doc_id', 'target']], on='doc_id', how='inner')\n",
    "    titles['title'] += ' '\n",
    "    titles['title'].fillna(' ', inplace=True)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    \n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(title, group_num, bad_words):\n",
    "    \n",
    "#     print(title)\n",
    "    title = title.lower()\n",
    "    \n",
    "    title = re.sub(r'\\W', '  ', title)\n",
    "    \n",
    "    for i in bad_words[group_num-1]:\n",
    "            title = title.replace(' ' + i + ' ', ' ')\n",
    "    title = re.sub(r'\\s+', ' ', title)\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_words_cleaner(bad_words, table_name='./data/unversal_table_with_bad_words.csv' ):\n",
    "                            #dict: {group_1 : bad_words_1,\n",
    "                            #       .....................\n",
    "                            #       group_n : bad_words_n}     \n",
    "\n",
    "#     print(len(df))\n",
    "    \n",
    "    df = pd.read_csv(table_name)\n",
    "    df.fillna('', inplace=True)\n",
    "    df['title'] = df[['title', 'group_id']].apply(lambda x: cleaning(*x, bad_words), axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Porter:\n",
    "    PERFECTIVEGROUND =  re.compile(u\"((ив|ивши|ившись|ыв|ывши|ывшись)|((?<=[ая])(в|вши|вшись)))$\")\n",
    "    REFLEXIVE = re.compile(u\"(с[яь])$\")\n",
    "    ADJECTIVE = re.compile(u\"(ее|ие|ые|ое|ими|ыми|ей|ий|ый|ой|ем|им|ым|ом|его|ого|ему|ому|их|ых|ую|юю|ая|яя|ою|ею)$\")\n",
    "    PARTICIPLE = re.compile(u\"((ивш|ывш|ующ)|((?<=[ая])(ем|нн|вш|ющ|щ)))$\")\n",
    "    VERB = re.compile(u\"((ила|ыла|ена|ейте|уйте|ите|или|ыли|ей|уй|ил|ыл|им|ым|ен|ило|ыло|ено|ят|ует|уют|ит|ыт|ены|ить|ыть|ишь|ую|ю)|((?<=[ая])(ла|на|ете|йте|ли|й|л|ем|н|ло|но|ет|ют|ны|ть|ешь|нно)))$\")\n",
    "    NOUN = re.compile(u\"(а|ев|ов|ие|ье|е|иями|ями|ами|еи|ии|и|ией|ей|ой|ий|й|иям|ям|ием|ем|ам|ом|о|у|ах|иях|ях|ы|ь|ию|ью|ю|ия|ья|я)$\")\n",
    "    RVRE = re.compile(u\"^(.*?[аеиоуыэюя])(.*)$\")\n",
    "    DERIVATIONAL = re.compile(u\".*[^аеиоуыэюя]+[аеиоуыэюя].*ость?$\")\n",
    "    DER = re.compile(u\"ость?$\")\n",
    "    SUPERLATIVE = re.compile(u\"(ейше|ейш)$\")\n",
    "    I = re.compile(u\"и$\")\n",
    "    P = re.compile(u\"ь$\")\n",
    "    NN = re.compile(u\"нн$\")\n",
    "\n",
    "    def stem(string):\n",
    "        \n",
    "        changed = ''\n",
    "        \n",
    "        string = string.lower()\n",
    "\n",
    "        for word in string.split():\n",
    "            if not word.isdigit():\n",
    "                word = word.replace(u'ё', u'е')\n",
    "                m = re.match(Porter.RVRE, word)\n",
    "\n",
    "                if m and m.groups():\n",
    "                    pre = m.group(1)\n",
    "                    rv = m.group(2)\n",
    "                    temp = Porter.PERFECTIVEGROUND.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = Porter.REFLEXIVE.sub('', rv, 1)\n",
    "                        temp = Porter.ADJECTIVE.sub('', rv, 1)\n",
    "                        if temp != rv:\n",
    "                            rv = temp\n",
    "                            rv = Porter.PARTICIPLE.sub('', rv, 1)\n",
    "                        else:\n",
    "                            temp = Porter.VERB.sub('', rv, 1)\n",
    "                            if temp == rv:\n",
    "                                rv = Porter.NOUN.sub('', rv, 1)\n",
    "                            else:\n",
    "                                rv = temp\n",
    "                    else:\n",
    "                        rv = temp\n",
    "\n",
    "                    rv = Porter.I.sub('', rv, 1)\n",
    "\n",
    "                    if re.match(Porter.DERIVATIONAL, rv):\n",
    "                        rv = Porter.DER.sub('', rv, 1)\n",
    "\n",
    "                    temp = Porter.P.sub('', rv, 1)\n",
    "                    if temp == rv:\n",
    "                        rv = Porter.SUPERLATIVE.sub('', rv, 1)\n",
    "                        rv = Porter.NN.sub(u'н', rv, 1)\n",
    "                    else:\n",
    "                        rv = temp\n",
    "                    word = pre+rv\n",
    "\n",
    "            changed += word + ' '\n",
    "\n",
    "        return changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_create(mode, groups_titledata):\n",
    "    \n",
    "    if mode == 'train':\n",
    "        y = []      \n",
    "    X = []\n",
    "    groups_train = []\n",
    "    \n",
    "    for new_group in groups_titledata:\n",
    "        docs = groups_titledata[new_group]\n",
    "        \n",
    "        for k, info in enumerate(docs):\n",
    "            \n",
    "            doc_id = info[0]\n",
    "            title = info[1]\n",
    "            \n",
    "            if mode == 'train':\n",
    "                target_id = info[2]\n",
    "                y.append(target_id)\n",
    "                \n",
    "            groups_train.append(new_group)\n",
    "            all_dist = []\n",
    "            words = set(title.strip().split())\n",
    "            \n",
    "            for j in range(0, len(docs)):\n",
    "                if k == j:\n",
    "                    continue\n",
    "                info = docs[j]\n",
    "                doc_id_j = info[0]\n",
    "                title_j = info[1]\n",
    "\n",
    "                words_j = set(title_j.strip().split())\n",
    "                all_dist.append(len(words.intersection(words_j)))\n",
    "                \n",
    "            X.append(sorted(all_dist, reverse=True)[0:25])\n",
    "            \n",
    "    X = np.array(X)\n",
    "    \n",
    "    if mode == 'train':\n",
    "        y = np.array(y)\n",
    "    \n",
    "    groups_train = np.array(groups_train)\n",
    "\n",
    "    if mode == 'train':\n",
    "        print(X.shape, y.shape, groups_train.shape)\n",
    "        return X, y, groups_train\n",
    "    else:\n",
    "        print(X.shape, groups_train.shape)\n",
    "        return X, groups_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_info_dict(mode, doc_to_title):\n",
    "    \n",
    "    data = pd.read_csv('./data/{}_groups.csv'.format(mode))\n",
    "\n",
    "    titledata = {}\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        \n",
    "        new_doc = data.iloc[i]\n",
    "        doc_group = new_doc['group_id']\n",
    "        doc_id = new_doc['doc_id']\n",
    "            \n",
    "        title = doc_to_title[doc_id]\n",
    "        \n",
    "        if doc_group not in titledata:\n",
    "            titledata[doc_group] = []\n",
    "            \n",
    "        if mode == 'train':\n",
    "            titledata[doc_group].append((doc_id, title, new_doc['target']))\n",
    "        else:\n",
    "            titledata[doc_group].append((doc_id, title))\n",
    "        \n",
    "    return titledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuple_x(a1, a2):\n",
    "    return a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easy_launch():\n",
    "    \n",
    "    doc_to_title = {}\n",
    "    with open('./data/unversal_table.csv') as f:\n",
    "        for num_line, line in enumerate(f):\n",
    "            if num_line == 0:\n",
    "                continue\n",
    "\n",
    "            line = line.replace('\\t', ',')\n",
    "            data = line.strip().split(',')\n",
    "\n",
    "            doc_id = int(data[0])\n",
    "            if len(data) == 1:\n",
    "                title = ''\n",
    "            else:\n",
    "                title = data[1]\n",
    "            doc_to_title[doc_id] = title\n",
    "            \n",
    "    print('doc titles dict len = {}'.format(len(doc_to_title)))\n",
    "    \n",
    "    train_titledata = title_info_dict('train', doc_to_title)\n",
    "    test_titledata = title_info_dict('test', doc_to_title)\n",
    "    \n",
    "    X_train, y_train, groups_train = features_create('train', train_titledata)\n",
    "    X_test, groups_test = features_create('test', test_titledata)\n",
    "    \n",
    "    return X_train, y_train, X_test, groups_train, groups_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    \n",
    "    result = []\n",
    "    for elem in x:\n",
    "        if hasattr(elem, \"__iter__\") and not isinstance(elem, str):\n",
    "            result.extend(flatten(elem))\n",
    "        else:\n",
    "            result.append(elem)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_concat(list1, list2):\n",
    "    \n",
    "    len1 = len(list1)\n",
    "    len2 = len(list2)\n",
    "    \n",
    "    return [[list1[i], list2[j]] for i in range(len1) for j in range(len2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinations(params):\n",
    "    \n",
    "    list_ = []\n",
    "    for value in params.values():\n",
    "        list_.append(value)\n",
    "\n",
    "    tmp = reduce(lambda x, y: list_concat(x, y), list_)\n",
    "\n",
    "    res = []\n",
    "    for elem in tmp:\n",
    "        param_list = flatten(elem)\n",
    "        param_dict = dict(zip(params.keys(), param_list))\n",
    "        res.append(param_dict)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frange(start, stop, step):\n",
    "    i = start\n",
    "    while i < stop:\n",
    "        yield i\n",
    "        i += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(X_train, train_target, model, params, folds_gen_func, groups_num=10, thresholds=[0.27], **kwargs):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train) \n",
    "    \n",
    "    main_res = []\n",
    "    for param_set in combinations(params):\n",
    "        \n",
    "        print(param_set)        \n",
    "        exact_model = model(**param_set) \n",
    "        \n",
    "        fold_generator = folds_gen_func(groups_num)\n",
    "        \n",
    "        for th in thresholds:\n",
    "    #         th = 0.27\n",
    "            res = []\n",
    "            for train_index, test_index in fold_generator.split(X_train, train_target, **kwargs):\n",
    "\n",
    "                exact_model.fit(scaler.transform(X_train[train_index]), train_target[train_index])\n",
    "\n",
    "                y_pred = [0 if val < th else 1 for val in exact_model.predict_proba(scaler.transform(X_train[test_index]))[:,1]]\n",
    "\n",
    "                score = metrics.f1_score(train_target[test_index],\\\n",
    "                                                y_pred)\n",
    "    #               print('threshold = {}, score = {}'.format(th, score))\n",
    "\n",
    "                res.append(score)\n",
    "        #                                       exact_model.predict(scaler.transform(X_train[test_index]))))\n",
    "\n",
    "\n",
    "            mean = sum(res)/len(res)\n",
    "            print(mean)\n",
    "#             print('threshold = {}, score = {}'.format(th, mean))\n",
    "            main_res.append((mean, param_set, th))\n",
    "    \n",
    "    best = main_res[np.argmax([res[0] for res in main_res])]\n",
    "    print('--------max-------')\n",
    "    print(best)\n",
    "    \n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняет решение\n",
    "\n",
    "def save_submission(y_pred):\n",
    "\n",
    "    data = pd.read_csv('data/test_groups.csv')\n",
    "    print('len data = ', len(data))\n",
    "    data['target'] = y_pred\n",
    "    \n",
    "    data = data.drop(['group_id', 'doc_id'], axis=1)\n",
    "\n",
    "    data.to_csv(\"submission.csv\", index=False)\n",
    "    \n",
    "    info = np.unique(data['target'], return_counts=True)\n",
    "    \n",
    "    if info[0].shape[0] > 1:\n",
    "        \n",
    "        print('0: {}, 1: {}'.format(info[1][0], info[1][1]))\n",
    "        if info[1][1] > 6000 or info[1][1] < 2500:\n",
    "            print('Your submisson is shit')\n",
    "#         elif info[1][1] > 4500:\n",
    "#             print('Your submisson is probably shit')\n",
    "    else:\n",
    "        print('There are only {} in submission'.format(info[0][0]))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, X_test, train_target, model, scaler=None, **kwargs):\n",
    "    \n",
    "    curr_model = model(**kwargs)\n",
    "    \n",
    "    if scaler is not None:\n",
    "        \n",
    "        your_scaler = scaler()\n",
    "        your_scaler.fit(X_train)\n",
    "        X_train = your_scaler.transform(X_train)\n",
    "        X_test = your_scaler.transform(X_test)\n",
    "        \n",
    "    curr_model.fit(X_train, train_target)\n",
    "#     y_pred = curr_model.predict(X_test)\n",
    "    th = 0.27\n",
    "    y_pred = [0 if val < th else 1 for val in curr_model.predict_proba(X_test)[:,1]]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming_titles(df):\n",
    "    stemming = Porter\n",
    "    return df['title'].apply(lambda x: stemming.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pymorphy2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-02ad2fd98c90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMorphAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pymorphy2' is not defined"
     ]
    }
   ],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лемматизация \n",
    "\n",
    "def str_parser(words_): \n",
    "    global j \n",
    "    new_string = '' \n",
    "\n",
    "    for i in re.findall(r'\\b[а-я]{1,20}\\b', words_): \n",
    "        new_string += (morph.parse(i)[0].normal_form) + ' ' \n",
    "\n",
    "    for i in re.findall(r'\\b[a-z]{1,20}\\b', words_): \n",
    "        new_string += (lemmatizer.lemmatize(i)) + ' ' \n",
    "\n",
    "    j += 1 \n",
    "    if(j % 1000 == 0): \n",
    "        print(j, '/28317 loaded') \n",
    "\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatization(df):\n",
    "    \n",
    "    return df['title'].apply(lambda x: str_parser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def titles_extraction(apply_stemming=True, apply_lemmatization=True, table_name=None):\n",
    "    \n",
    "    if table_name is None:\n",
    "        df_train = pd.read_csv('data/core_train.csv')\n",
    "        df_test = pd.read_csv('data/core_test.csv')\n",
    "        df_train.fillna(' ', inplace=True)\n",
    "        df_test.fillna(' ', inplace=True)\n",
    "\n",
    "        titles_df = pd.concat([df_train, df_test])\n",
    "\n",
    "        titles = pd.DataFrame({'doc_id': titles_df['doc_id'] ,\n",
    "                               'group_id': titles_df['group_id'],\n",
    "                               'title': titles_df['title'] + titles_df['h1']})\n",
    "    #                            'title': titles_df['h2'] + titles_df['h3'] + titles_df['a']})\n",
    "    else:\n",
    "        titles_df = pd.read_csv(table_name)\n",
    "        titles_df.fillna(' ', inplace=True)\n",
    "        titles = pd.DataFrame({'doc_id': titles_df['doc_id'] ,\n",
    "                               'group_id': titles_df['group_id'],\n",
    "                               'title': titles_df['body']})\n",
    "    if apply_stemming:\n",
    "        titles['title'] = stemming_titles(titles)\n",
    "    if apply_lemmatization:\n",
    "        titles['title'] = lemmatization(titles)\n",
    "    \n",
    "    titles = titles[['title', 'group_id']].groupby('group_id').sum()['title']\n",
    "\n",
    "    titles = titles.apply(lambda x: cleaner(x))\n",
    "    titles = titles.values\n",
    "\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_words(all_titles, X, importance, threshold=0.015, group_number=None, ngram=(1,2)):\n",
    "    \n",
    "#     print(all_titles[group_number], group_number)\n",
    "    if group_number is not None:\n",
    "        \n",
    "        print('group_number = ', group_number)\n",
    "        \n",
    "        group_titles = importance[group_number]\n",
    "        group_titles = group_titles[0]\n",
    "        \n",
    "        new_dict = {v: k for k, v in X.vocabulary_.items()}\n",
    "        \n",
    "        array = np.where(np.bitwise_and(group_titles.toarray()!=0, group_titles.toarray()<threshold))[1]\n",
    "#         print(len(group_titles.toarray()[np.where(np.bitwise_and(group_titles.toarray()!=0, group_titles.toarray()<threshold))]))\n",
    "#         print('--------------',len([new_dict[index] for index in array]))\n",
    "        return [new_dict[index] for index in array]\n",
    "    \n",
    "    else:\n",
    "\n",
    "        group_bad_words = {group: bad_words(all_titles, importance, X, threshold, group, ngram) for group in range(len(all_titles))}\n",
    "\n",
    "        return group_bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_titles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a23413b36dfe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_titles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_titles' is not defined"
     ]
    }
   ],
   "source": [
    "one = all_titles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = titles_extraction(apply_stemming=False, apply_lemmatization=False, table_name='data/CORE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = [0.007, 0.008]#, 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.02]\n",
    "for t in threshold:\n",
    "    print(t)\n",
    "    X = TfidfVectorizer(min_df=5, max_df=0.7)\n",
    "    importance = X.fit_transform(all_titles)\n",
    "    words = bad_words(all_titles, X, importance, t, 1)\n",
    "    print(words)\n",
    "    print(np.unique(all_titles[1].split()).shape, np.unique(words).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X = TfidfVectorizer()\n",
    "importance = X.fit_transform(all_titles)\n",
    "words = bad_words(all_titles, importance, X, 0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>group_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15731</td>\n",
       "      <td>ваз зам подшипник ступиц нив зам подшипник сту...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14829</td>\n",
       "      <td>ваз опт соч сравн цен куп потребительск товар ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15764</td>\n",
       "      <td>куп ступиц лад трансмисс переходн ступиц цен з...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17669</td>\n",
       "      <td>классик learn center</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14852</td>\n",
       "      <td>ступиц нив зам подшипник сво рук ступиц нив ка...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28312</th>\n",
       "      <td>16637</td>\n",
       "      <td>ответ полезн куша творог утр худет поправ обед...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>16759</td>\n",
       "      <td>творог полезн свойств лечен творог лечебн свой...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28314</th>\n",
       "      <td>15358</td>\n",
       "      <td>творог полезн свойств творог творог</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28315</th>\n",
       "      <td>17287</td>\n",
       "      <td>ответ чем полезн творог чем полезн творог mail</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28316</th>\n",
       "      <td>16026</td>\n",
       "      <td>творог польз вред как выбира продукт фитнес зд...</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id                                              title  group_id\n",
       "0       15731  ваз зам подшипник ступиц нив зам подшипник сту...         1\n",
       "1       14829  ваз опт соч сравн цен куп потребительск товар ...         1\n",
       "2       15764  куп ступиц лад трансмисс переходн ступиц цен з...         1\n",
       "3       17669                              классик learn center          1\n",
       "4       14852  ступиц нив зам подшипник сво рук ступиц нив ка...         1\n",
       "...       ...                                                ...       ...\n",
       "28312   16637  ответ полезн куша творог утр худет поправ обед...       309\n",
       "28313   16759  творог полезн свойств лечен творог лечебн свой...       309\n",
       "28314   15358               творог полезн свойств творог творог        309\n",
       "28315   17287    ответ чем полезн творог чем полезн творог mail        309\n",
       "28316   16026  творог польз вред как выбира продукт фитнес зд...       309\n",
       "\n",
       "[28317 rows x 3 columns]"
      ]
     },
     "execution_count": 678,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df = bad_words_cleaner(words)\n",
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28199\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed</th>\n",
       "      <th>non processed</th>\n",
       "      <th>differ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28312</th>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28314</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28315</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28316</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       processed  non processed  differ\n",
       "0              8              8       0\n",
       "1             12             12       0\n",
       "2             10             11       1\n",
       "3              3              3       0\n",
       "4             12             13       1\n",
       "...          ...            ...     ...\n",
       "28312         18             20       2\n",
       "28313         14             18       4\n",
       "28314          5              6       1\n",
       "28315          8              8       0\n",
       "28316         13             13       0\n",
       "\n",
       "[28317 rows x 3 columns]"
      ]
     },
     "execution_count": 679,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/unversal_table_with_bad_words.csv')\n",
    "df.fillna(' ', inplace=True)\n",
    "\n",
    "info = pd.DataFrame()\n",
    "\n",
    "info['processed'] = processed_df['title'].apply(lambda x: len(x.split()))\n",
    "info['non processed'] = df['title'].apply(lambda x: len(x.split()))\n",
    "info['differ'] = info['non processed'] - info['processed']\n",
    "\n",
    "print(info['differ'].max())\n",
    "info[info.differ == info['differ'].max()]\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('./data/unversal_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/core_train.csv')\n",
    "df_test = pd.read_csv('data/core_test.csv')\n",
    "df_train.fillna(' ', inplace=True)\n",
    "df_test.fillna(' ', inplace=True)\n",
    "titles_df = pd.concat([df_train, df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles = pd.DataFrame({'doc_id': titles_df['doc_id'] ,\n",
    "                       'title': titles_df['title'] + titles_df['h1'],\n",
    "#                        'title': titles_df['h2'] + titles_df['h3'] + titles_df['a'],\n",
    "                       'group_id': titles_df['group_id']})\n",
    "\n",
    "titles['title'] = stemming_titles(titles)\n",
    "titles['title'] = lemmatization(titles)\n",
    "\n",
    "# titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles.to_csv('./data/unversal_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# processed_df['title'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(x):\n",
    "    unique_words = np.unique(x.split())\n",
    "    text = str()\n",
    "    for word in unique_words:\n",
    "        text += word + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['title_unique'] = processed_df['title'].apply(lambda x: unique(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.to_csv('./data/no_bad_words_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc titles dict len = 28026\n",
      "(11690, 25) (11690,) (11690,)\n",
      "(16627, 25) (16627,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, groups_train, groups_test = easy_launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': [0.07, 0.08],\n",
    "#           'n_estimators': [372, 374]}\n",
    "          'n_estimators': [175, 180, 185]}\n",
    "groups_train = pd.read_csv('data/train_groups.csv')['group_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.07, 'n_estimators': 175}\n",
      "0.6192471631923653\n",
      "{'learning_rate': 0.07, 'n_estimators': 180}\n",
      "0.6193823034312785\n",
      "{'learning_rate': 0.07, 'n_estimators': 185}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-437-8c40b246bd5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGroupKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-325-2fae6b177f85>\u001b[0m in \u001b[0;36mvalidation\u001b[0;34m(X_train, train_target, model, params, folds_gen_func, groups_num, thresholds, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfold_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                 \u001b[0mexact_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mth\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexact_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         n_stages = self._fit_stages(\n\u001b[1;32m   1536\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1537\u001b[0;31m             sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1592\u001b[0m             raw_predictions = self._fit_stage(\n\u001b[1;32m   1593\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1594\u001b[0;31m                 random_state, X_idx_sorted, X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1596\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1243\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1245\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1223\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1225\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/sphere-py37/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = validation(X_train, y_train, GradientBoostingClassifier, params, GroupKFold, groups=groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len data =  16627\n",
      "0: 10613, 1: 6014\n",
      "Your submisson is shit\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict(X_train, X_test, y_train, GradientBoostingClassifier, StandardScaler, **best[1])\n",
    "data = save_submission(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "    df = pd.read_csv('./data/unversal_table.csv')\n",
    "    df.fillna(' ', inplace=True)\n",
    "    corpus = df['title'].values\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "    X = vectorizer.fit_transform(corpus)\n",
    "        \n",
    "    X = X.toarray()\n",
    "    for \n",
    "#     length = 0\n",
    "    \n",
    "#     for group_num in np.unique(df['group_id']):\n",
    "        \n",
    "#         group_length = len(df[df.group_id==group_num])\n",
    "#         group_titles = X[length:length + group_length]\n",
    "#         length += group_length\n",
    "        \n",
    "#         features = count_distances(group_titles)\n",
    "\n",
    "#         np.save('group_features/{}'.format(group_num), features)\n",
    "#         print('Скачалась группа:', group_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacking(X_train, X_test, train_target, models, params, folds_gen_func, groups_num=10, thresholds=[0.27], **kwargs):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "        \n",
    "    main_res_train = np.zeros(shape=(train_target.shape, 1))\n",
    "    main_res_test = np.zeros(shape=(X_test.shape[0], 1))\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        print(params[model])        \n",
    "        exact_model = model(params[model]) \n",
    "        \n",
    "        fold_generator = folds_gen_func(groups_num)\n",
    "        \n",
    "        res_train = np.zeroes(train_target.shape)\n",
    "        res_test = np.zeroes(X_test.shape[0])\n",
    "        \n",
    "        for train_index, test_index in fold_generator.split(X_train, train_target, **kwargs):\n",
    "            \n",
    "            scaler.fit(X_train)\n",
    "            exact_model.fit(scaler.transform(X_train[train_index]), train_target[train_index])\n",
    "\n",
    "            y_pred_train = exact_model.predict_proba(scaler.transform(X_train[test_index]))\n",
    "            res_train[test_index] = y_pred_train \n",
    "            \n",
    "            scaler.fit(X_test)\n",
    "            y_pred_test = exact_model.predict_proba(scaler.transform(X_test))\n",
    "\n",
    "            res_test += y_pred_test\n",
    "            \n",
    "        res_test /= groups_num\n",
    "        main_res_train = np.hstack((main_res_train, res_train[:, np.newaxis]))\n",
    "        main_res_test = np.hstack((main_res_test, res_test[:, np.newaxis]))   \n",
    "\n",
    "    return main_res_train, main_res_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [GradientBoostingClassifier, RandomForestClassifier, KNeighborsClassifier]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params[GradientBoostingClassifier] = {'learning_rate': [0.06],\n",
    "                                      'n_estimators' : [150]}\n",
    "params[RandomForestClassifier] = {'n_estimators': [1300], \n",
    "                                  'criterion': ['gini'], \n",
    "                                  'max_depth': [7], \n",
    "                                  'n_jobs': [-1]}\n",
    "params[KNeighborsClassifier] = {'algorithm': ['ball_tree'],\n",
    "                                'leaf_size': [10],\n",
    "                                'n_neighbors': [75],\n",
    "                                'p': [1],\n",
    "                                'n_jobs': [-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': [0.06], 'n_estimators': [150]}"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking(X_train, X_test, train_target, models, params, GroupKFold, groups=groups_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train, RandomForestClassifier, params, GroupKFold, groups=groups_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 699,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[[5,7,8]] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 2., 3., 0.])"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4, 5],\n",
    "              [6, 7, 8, 9, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.],\n",
       "       [6.]])"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(a, axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.hstack((a, np.mean(a, axis=1)[:, np.newaxis], np.std(a, axis=1)[:, np.newaxis], np.median(a, axis=1)[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.read_csv('data/CORE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = main_df['body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "word, num = np.unique(body[100].split(), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ремонт', 33),\n",
       " ('подшипник', 28),\n",
       " ('свой', 26),\n",
       " ('мост', 25),\n",
       " ('шестерня', 24),\n",
       " ('ваза', 23),\n",
       " ('передний', 23)]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(zip(word, num)), key=lambda pair: pair[1], reverse=True)[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "def body_change(text):\n",
    "    global j\n",
    "    word, num = np.unique(text.split(), return_counts=True)\n",
    "    words = sorted(list(zip(word, num)), key=lambda pair: pair[1], reverse=True)[:7]\n",
    "    text = ' '.join(list(map(lambda x: x[0], words)))\n",
    "    j+=1 \n",
    "    print(j)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles_df = pd.DataFrame()\n",
    "# j=0\n",
    "# titles_df['body'] = main_df['body'].apply(lambda x: body_change(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.DataFrame({'doc_id': main_df['doc_id'] ,\n",
    "                       'title': titles_df['body'],\n",
    "#                        'title': titles_df['title'] + titles_df['h1'],\n",
    "#                        'title': titles_df['h2'] + titles_df['h3'] + titles_df['a'],\n",
    "                       'group_id': main_df['group_id']})\n",
    "titles.to_csv('./data/unversal_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>title</th>\n",
       "      <th>h1</th>\n",
       "      <th>strong</th>\n",
       "      <th>body</th>\n",
       "      <th>group_id</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ваза зам подшипник ступица нива</td>\n",
       "      <td>зам подшипник ступица</td>\n",
       "      <td>разборк передна тормозна механизм проверк регу...</td>\n",
       "      <td>ваза замена подшипник ступица нива автомануал ...</td>\n",
       "      <td>1</td>\n",
       "      <td>15731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ваза опт соч сравна цена купа потребительск то...</td>\n",
       "      <td>ваза опт соч</td>\n",
       "      <td></td>\n",
       "      <td>ваза оптом сочи сравнить цена купить потребите...</td>\n",
       "      <td>1</td>\n",
       "      <td>14829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>купа ступица лада калин трансмисс переходна ст...</td>\n",
       "      <td>ступица лада калин</td>\n",
       "      <td>лада калин предложный</td>\n",
       "      <td>купить ступица лада калин трансмиссия переходн...</td>\n",
       "      <td>1</td>\n",
       "      <td>15764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>классик</td>\n",
       "      <td>learn center</td>\n",
       "      <td>номенклатура цена</td>\n",
       "      <td>классика главный продукция интернет магазин до...</td>\n",
       "      <td>1</td>\n",
       "      <td>17669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ступица нива зам подшипник сво рука</td>\n",
       "      <td>ступица нива как провест ремонт замена подшипник</td>\n",
       "      <td>нива шеврол</td>\n",
       "      <td>ступица нива замена подшипник свой рука контак...</td>\n",
       "      <td>1</td>\n",
       "      <td>14852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28312</th>\n",
       "      <td>28312</td>\n",
       "      <td>28312</td>\n",
       "      <td>28312</td>\n",
       "      <td>ответ полезна куш творог утро есл худо поправт...</td>\n",
       "      <td>полезна куш творог утро есл худо поправть обед...</td>\n",
       "      <td>лучш ответ остальна ответ похожий вопрос такж ...</td>\n",
       "      <td>ответ полезно кушать творог утро если худеть п...</td>\n",
       "      <td>309</td>\n",
       "      <td>16637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>28313</td>\n",
       "      <td>28313</td>\n",
       "      <td>28313</td>\n",
       "      <td>творог полезна свойство леченый творог женск с...</td>\n",
       "      <td>лечебн свойство продукт буква творог полезна с...</td>\n",
       "      <td></td>\n",
       "      <td>творог полезный свойство лечение творог женски...</td>\n",
       "      <td>309</td>\n",
       "      <td>16759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28314</th>\n",
       "      <td>28314</td>\n",
       "      <td>28314</td>\n",
       "      <td>28314</td>\n",
       "      <td>творог полезна опасна свойство творог</td>\n",
       "      <td>творог</td>\n",
       "      <td></td>\n",
       "      <td>творог полезный опасный свойство творог присое...</td>\n",
       "      <td>309</td>\n",
       "      <td>15358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28315</th>\n",
       "      <td>28315</td>\n",
       "      <td>28315</td>\n",
       "      <td>28315</td>\n",
       "      <td>ответ чем полезть творог mail</td>\n",
       "      <td>чем полезть творог</td>\n",
       "      <td>лучш ответ остальна ответ похожий вопрос такж ...</td>\n",
       "      <td>ответ чем полезный творог проектывсё категория...</td>\n",
       "      <td>309</td>\n",
       "      <td>17287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28316</th>\n",
       "      <td>28316</td>\n",
       "      <td>28316</td>\n",
       "      <td>28316</td>\n",
       "      <td>творог польза вред как выбира продукт фитнес з...</td>\n",
       "      <td>творог польза вред</td>\n",
       "      <td>срок годност сутки изготовитеть цена срок годн...</td>\n",
       "      <td>творог польза вред как выбирать продукт фитнес...</td>\n",
       "      <td>309</td>\n",
       "      <td>16026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1  \\\n",
       "0               0             0               0   \n",
       "1               1             1               1   \n",
       "2               2             2               2   \n",
       "3               3             3               3   \n",
       "4               4             4               4   \n",
       "...           ...           ...             ...   \n",
       "28312       28312         28312           28312   \n",
       "28313       28313         28313           28313   \n",
       "28314       28314         28314           28314   \n",
       "28315       28315         28315           28315   \n",
       "28316       28316         28316           28316   \n",
       "\n",
       "                                                   title  \\\n",
       "0                       ваза зам подшипник ступица нива    \n",
       "1      ваза опт соч сравна цена купа потребительск то...   \n",
       "2      купа ступица лада калин трансмисс переходна ст...   \n",
       "3                                               классик    \n",
       "4                   ступица нива зам подшипник сво рука    \n",
       "...                                                  ...   \n",
       "28312  ответ полезна куш творог утро есл худо поправт...   \n",
       "28313  творог полезна свойство леченый творог женск с...   \n",
       "28314             творог полезна опасна свойство творог    \n",
       "28315                     ответ чем полезть творог mail    \n",
       "28316  творог польза вред как выбира продукт фитнес з...   \n",
       "\n",
       "                                                      h1  \\\n",
       "0                                 зам подшипник ступица    \n",
       "1                                          ваза опт соч    \n",
       "2                                    ступица лада калин    \n",
       "3                                          learn center    \n",
       "4      ступица нива как провест ремонт замена подшипник    \n",
       "...                                                  ...   \n",
       "28312  полезна куш творог утро есл худо поправть обед...   \n",
       "28313  лечебн свойство продукт буква творог полезна с...   \n",
       "28314                                            творог    \n",
       "28315                                чем полезть творог    \n",
       "28316                                творог польза вред    \n",
       "\n",
       "                                                  strong  \\\n",
       "0      разборк передна тормозна механизм проверк регу...   \n",
       "1                                                          \n",
       "2                                 лада калин предложный    \n",
       "3                                     номенклатура цена    \n",
       "4                                           нива шеврол    \n",
       "...                                                  ...   \n",
       "28312  лучш ответ остальна ответ похожий вопрос такж ...   \n",
       "28313                                                      \n",
       "28314                                                      \n",
       "28315  лучш ответ остальна ответ похожий вопрос такж ...   \n",
       "28316  срок годност сутки изготовитеть цена срок годн...   \n",
       "\n",
       "                                                    body  group_id  doc_id  \n",
       "0      ваза замена подшипник ступица нива автомануал ...         1   15731  \n",
       "1      ваза оптом сочи сравнить цена купить потребите...         1   14829  \n",
       "2      купить ступица лада калин трансмиссия переходн...         1   15764  \n",
       "3      классика главный продукция интернет магазин до...         1   17669  \n",
       "4      ступица нива замена подшипник свой рука контак...         1   14852  \n",
       "...                                                  ...       ...     ...  \n",
       "28312  ответ полезно кушать творог утро если худеть п...       309   16637  \n",
       "28313  творог полезный свойство лечение творог женски...       309   16759  \n",
       "28314  творог полезный опасный свойство творог присое...       309   15358  \n",
       "28315  ответ чем полезный творог проектывсё категория...       309   17287  \n",
       "28316  творог польза вред как выбирать продукт фитнес...       309   16026  \n",
       "\n",
       "[28317 rows x 9 columns]"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# j=0\n",
    "# titles_df['strong'] = main_df['strong'].apply(lambda x: body_change(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        снятой зазор опора передна подшипник проверк р...\n",
       "1                                                         \n",
       "2                                    калин лада предложный\n",
       "3                                        номенклатура цена\n",
       "4                                              нива шеврол\n",
       "                               ...                        \n",
       "28312      ответ вопрос лучш остальна похожий спрашив такж\n",
       "28313                                                     \n",
       "28314                                                     \n",
       "28315      ответ вопрос лучш остальна похожий спрашив такж\n",
       "28316      годност изготовитеть срок цена сутки плохой сыр\n",
       "Name: strong, Length: 28317, dtype: object"
      ]
     },
     "execution_count": 793,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df['strong']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['strong len'] = main_df['strong'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# titles_df['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_tags_counter(doc_id):\n",
    "    count = 0\n",
    "    read_file = open('./content/' + str(doc_id) + '.dat', 'r', encoding = 'utf-8')\n",
    "    text = read_file.read()\n",
    "    pattern = re.findall(r'<font color=', text)\n",
    "    return len(pattern)\n",
    "\n",
    "def link_tags_counter(doc_id):\n",
    "    count = 0\n",
    "    read_file = open('./content/' + str(doc_id) + '.dat', 'r', encoding = 'utf-8')\n",
    "    text = read_file.read()\n",
    "    pattern = re.findall(r'<a href=', text)\n",
    "    return len(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_groups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['br_num'] = train['doc_id'].apply(lambda x: img_tags_counter(x))\n",
    "# train['href_num'] = train['doc_id'].apply(lambda x: link_tags_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(train[train.target == 1]['br_num'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5515668147436665"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.target == 0]['br_num'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.target == 1]['br_num'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train.target == 0]['br_num'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df['doc_id'] = main_df['doc_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df_new = pd.merge(titles_df, train[['doc_id', 'target']], on='doc_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>strong</th>\n",
       "      <th>len</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>strong len</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>подшипник ступица кулак поворотный снятие коль...</td>\n",
       "      <td>снятой зазор опора передна подшипник проверк р...</td>\n",
       "      <td>579</td>\n",
       "      <td>15731</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>отзыв ваза показать номер заказ цена rub</td>\n",
       "      <td></td>\n",
       "      <td>1535</td>\n",
       "      <td>14829</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>лада ступица передний апрель сбор оригинал нал...</td>\n",
       "      <td>калин лада предложный</td>\n",
       "      <td>1129</td>\n",
       "      <td>15764</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ваза тольятти дааз вис сбор задний левый</td>\n",
       "      <td>номенклатура цена</td>\n",
       "      <td>2582</td>\n",
       "      <td>17669</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>подшипник ступица нива колесо передний ремонт ...</td>\n",
       "      <td>нива шеврол</td>\n",
       "      <td>684</td>\n",
       "      <td>14852</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>время дата сообщение ответ что я весь</td>\n",
       "      <td></td>\n",
       "      <td>15067</td>\n",
       "      <td>26672</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11927</th>\n",
       "      <td>http url bitbon geschrieben von com news</td>\n",
       "      <td></td>\n",
       "      <td>28082</td>\n",
       "      <td>25838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>что я быть это весь для ты</td>\n",
       "      <td></td>\n",
       "      <td>15230</td>\n",
       "      <td>25703</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11929</th>\n",
       "      <td>шурыгин диана goo youtube говорят канал пусть</td>\n",
       "      <td>говор диана пустой шурыгин prodeundi весь мате...</td>\n",
       "      <td>6503</td>\n",
       "      <td>27885</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11930</th>\n",
       "      <td>смоленск ревизорро газа визит драка кафе енот</td>\n",
       "      <td></td>\n",
       "      <td>1277</td>\n",
       "      <td>27987</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11931 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      подшипник ступица кулак поворотный снятие коль...   \n",
       "1               отзыв ваза показать номер заказ цена rub   \n",
       "2      лада ступица передний апрель сбор оригинал нал...   \n",
       "3               ваза тольятти дааз вис сбор задний левый   \n",
       "4      подшипник ступица нива колесо передний ремонт ...   \n",
       "...                                                  ...   \n",
       "11926              время дата сообщение ответ что я весь   \n",
       "11927           http url bitbon geschrieben von com news   \n",
       "11928                         что я быть это весь для ты   \n",
       "11929      шурыгин диана goo youtube говорят канал пусть   \n",
       "11930      смоленск ревизорро газа визит драка кафе енот   \n",
       "\n",
       "                                                  strong    len  doc_id  \\\n",
       "0      снятой зазор опора передна подшипник проверк р...    579   15731   \n",
       "1                                                          1535   14829   \n",
       "2                                  калин лада предложный   1129   15764   \n",
       "3                                      номенклатура цена   2582   17669   \n",
       "4                                            нива шеврол    684   14852   \n",
       "...                                                  ...    ...     ...   \n",
       "11926                                                     15067   26672   \n",
       "11927                                                     28082   25838   \n",
       "11928                                                     15230   25703   \n",
       "11929  говор диана пустой шурыгин prodeundi весь мате...   6503   27885   \n",
       "11930                                                      1277   27987   \n",
       "\n",
       "       strong len  target  \n",
       "0              26       0  \n",
       "1               0       0  \n",
       "2               3       0  \n",
       "3               2       0  \n",
       "4               2       0  \n",
       "...           ...     ...  \n",
       "11926           0       0  \n",
       "11927           0       0  \n",
       "11928           0       0  \n",
       "11929          13       0  \n",
       "11930           0       0  \n",
       "\n",
       "[11931 rows x 6 columns]"
      ]
     },
     "execution_count": 821,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df_new['pic_num'] = titles_df_new['doc_id'].apply(lambda x: )\n",
    "titles_df_new['pic_num'] = titles_df_new['doc_id'].apply(lambda x: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "855.0"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df_new[titles_df_new.target == 1]['len'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2669.0"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df_new[titles_df_new.target == 0]['len'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201.6268126664693"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df_new[titles_df_new.target == 1]['len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11022.10874649205"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df_new[titles_df_new.target == 0]['len'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>strong</th>\n",
       "      <th>len</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>strong len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>подшипник ступица кулак поворотный снятие коль...</td>\n",
       "      <td>снятой зазор опора передна подшипник проверк р...</td>\n",
       "      <td>579</td>\n",
       "      <td>15731</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>отзыв ваза показать номер заказ цена rub</td>\n",
       "      <td></td>\n",
       "      <td>1535</td>\n",
       "      <td>14829</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>лада ступица передний апрель сбор оригинал нал...</td>\n",
       "      <td>калин лада предложный</td>\n",
       "      <td>1129</td>\n",
       "      <td>15764</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ваза тольятти дааз вис сбор задний левый</td>\n",
       "      <td>номенклатура цена</td>\n",
       "      <td>2582</td>\n",
       "      <td>17669</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>подшипник ступица нива колесо передний ремонт ...</td>\n",
       "      <td>нива шеврол</td>\n",
       "      <td>684</td>\n",
       "      <td>14852</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28312</th>\n",
       "      <td>год назад творог полезно mail вопрос есть</td>\n",
       "      <td>ответ вопрос лучш остальна похожий спрашив такж</td>\n",
       "      <td>400</td>\n",
       "      <td>16637</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>творог для сайт полезный свойство inmoment весь</td>\n",
       "      <td></td>\n",
       "      <td>771</td>\n",
       "      <td>16759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28314</th>\n",
       "      <td>творог при еда молоко он продукт свойство</td>\n",
       "      <td></td>\n",
       "      <td>1187</td>\n",
       "      <td>15358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28315</th>\n",
       "      <td>творог для кальций полезный год он белка</td>\n",
       "      <td>ответ вопрос лучш остальна похожий спрашив такж</td>\n",
       "      <td>945</td>\n",
       "      <td>17287</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28316</th>\n",
       "      <td>творог отправить ответить что продукт это молоко</td>\n",
       "      <td>годност изготовитеть срок цена сутки плохой сыр</td>\n",
       "      <td>3403</td>\n",
       "      <td>16026</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    body  \\\n",
       "0      подшипник ступица кулак поворотный снятие коль...   \n",
       "1               отзыв ваза показать номер заказ цена rub   \n",
       "2      лада ступица передний апрель сбор оригинал нал...   \n",
       "3               ваза тольятти дааз вис сбор задний левый   \n",
       "4      подшипник ступица нива колесо передний ремонт ...   \n",
       "...                                                  ...   \n",
       "28312          год назад творог полезно mail вопрос есть   \n",
       "28313    творог для сайт полезный свойство inmoment весь   \n",
       "28314          творог при еда молоко он продукт свойство   \n",
       "28315           творог для кальций полезный год он белка   \n",
       "28316   творог отправить ответить что продукт это молоко   \n",
       "\n",
       "                                                  strong   len  doc_id  \\\n",
       "0      снятой зазор опора передна подшипник проверк р...   579   15731   \n",
       "1                                                         1535   14829   \n",
       "2                                  калин лада предложный  1129   15764   \n",
       "3                                      номенклатура цена  2582   17669   \n",
       "4                                            нива шеврол   684   14852   \n",
       "...                                                  ...   ...     ...   \n",
       "28312    ответ вопрос лучш остальна похожий спрашив такж   400   16637   \n",
       "28313                                                      771   16759   \n",
       "28314                                                     1187   15358   \n",
       "28315    ответ вопрос лучш остальна похожий спрашив такж   945   17287   \n",
       "28316    годност изготовитеть срок цена сутки плохой сыр  3403   16026   \n",
       "\n",
       "       strong len  \n",
       "0              26  \n",
       "1               0  \n",
       "2               3  \n",
       "3               2  \n",
       "4               2  \n",
       "...           ...  \n",
       "28312           8  \n",
       "28313           0  \n",
       "28314           0  \n",
       "28315           8  \n",
       "28316          26  \n",
       "\n",
       "[28317 rows x 5 columns]"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_tag(doc_id):\n",
    "    \n",
    "    result = str()\n",
    "    file_ = open('./content/' + str(doc_id) + '.dat', 'r', encoding = 'utf-8')\n",
    "    text_ = file_.read()\n",
    "    soup = BeautifulSoup(text_, 'html')\n",
    "    \n",
    "    for i in soup.find_all('meta', attrs = {'name' : 'Keywords'}):\n",
    "        if i.find_all('content'):\n",
    "            if i.attrs['content'] == '':\n",
    "                \n",
    "    for i in soup.find_all('meta', attrs = {'name' : 'keywords'}):\n",
    "        if i.find_all('content'):\n",
    "            result += i.attrs['content'] + ' '\n",
    "    \n",
    "    if result != '':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_tag(doc_id):\n",
    "    global j \n",
    "    \n",
    "    result = str()\n",
    "    file_ = open('./content/' + str(doc_id) + '.dat', 'r', encoding = 'utf-8')\n",
    "    text_ = file_.read()\n",
    "    soup = BeautifulSoup(text_, 'html')\n",
    "    res = 0\n",
    "    \n",
    "    for i in soup.find_all('meta', attrs = {'name' : 'Keywords'}):\n",
    "        if i.find_all('content'):\n",
    "            result += i.attrs['content'] + ' '\n",
    "    for i in soup.find_all('meta', attrs = {'name' : 'keywords'}):\n",
    "        if i.find_all('content'):\n",
    "            result += i.attrs['content'] + ' '\n",
    "    \n",
    "#     result = result.lower()\n",
    "#     new_string = str()\n",
    "    \n",
    "#     result = steming.stem(result)\n",
    "    \n",
    "    if re.search(r'\\b[а-я]{1,20}\\b', result): \n",
    "#         new_string += (morph.parse(i)[0].normal_form) + ' ' \n",
    "        res = 1\n",
    "    \n",
    "    if re.search(r'\\b[a-z]{1,20}\\b', result):\n",
    "#         new_string += (lemmatizer.lemmatize(i)) + ' ' \n",
    "        res = 1\n",
    "    j+=1\n",
    "    print(j)\n",
    "    if res:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/unversal_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j=0\n",
    "# df['keyw'] = df['doc_id'].apply(lambda x: meta_tag(x))\n",
    "# # df['href_num'] = df['doc_id'].apply(lambda x: link_tags_counter(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.merge(df, titles_df[['doc_id', 'len']], on='doc_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['len'] = titles_df['len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pic_num'] = train['pic_num']\n",
    "df['href_num'] = train['href_num']\n",
    "df['b_num'] = train['b_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/unversal_table.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>title</th>\n",
       "      <th>group_id</th>\n",
       "      <th>len</th>\n",
       "      <th>pic_num</th>\n",
       "      <th>href_num</th>\n",
       "      <th>b_num</th>\n",
       "      <th>br_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15731</td>\n",
       "      <td>ваз зам подшипник ступиц нив зам подшипник сту...</td>\n",
       "      <td>1</td>\n",
       "      <td>579</td>\n",
       "      <td>32.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14829</td>\n",
       "      <td>ваз опт соч сравн цен куп потребительск товар ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1535</td>\n",
       "      <td>56.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15764</td>\n",
       "      <td>куп ступиц лад трансмисс переходн ступиц цен з...</td>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>43.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17669</td>\n",
       "      <td>классик learn center</td>\n",
       "      <td>1</td>\n",
       "      <td>2582</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14852</td>\n",
       "      <td>ступиц нив зам подшипник сво рук ступиц нив ка...</td>\n",
       "      <td>1</td>\n",
       "      <td>684</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28312</th>\n",
       "      <td>16637</td>\n",
       "      <td>ответ полезн куша творог утр есл худет поправ ...</td>\n",
       "      <td>309</td>\n",
       "      <td>400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28313</th>\n",
       "      <td>16759</td>\n",
       "      <td>творог полезн свойств лечен творог женск сайт ...</td>\n",
       "      <td>309</td>\n",
       "      <td>771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28314</th>\n",
       "      <td>15358</td>\n",
       "      <td>творог полезн опасн свойств творог творог</td>\n",
       "      <td>309</td>\n",
       "      <td>1187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28315</th>\n",
       "      <td>17287</td>\n",
       "      <td>ответ чем полезн творог чем полезн творог mail</td>\n",
       "      <td>309</td>\n",
       "      <td>945</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28316</th>\n",
       "      <td>16026</td>\n",
       "      <td>творог польз вред как выбира продукт фитнес зд...</td>\n",
       "      <td>309</td>\n",
       "      <td>3403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28317 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       doc_id                                              title  group_id  \\\n",
       "0       15731  ваз зам подшипник ступиц нив зам подшипник сту...         1   \n",
       "1       14829  ваз опт соч сравн цен куп потребительск товар ...         1   \n",
       "2       15764  куп ступиц лад трансмисс переходн ступиц цен з...         1   \n",
       "3       17669                              классик learn center          1   \n",
       "4       14852  ступиц нив зам подшипник сво рук ступиц нив ка...         1   \n",
       "...       ...                                                ...       ...   \n",
       "28312   16637  ответ полезн куша творог утр есл худет поправ ...       309   \n",
       "28313   16759  творог полезн свойств лечен творог женск сайт ...       309   \n",
       "28314   15358         творог полезн опасн свойств творог творог        309   \n",
       "28315   17287    ответ чем полезн творог чем полезн творог mail        309   \n",
       "28316   16026  творог польз вред как выбира продукт фитнес зд...       309   \n",
       "\n",
       "        len  pic_num  href_num  b_num  br_num  \n",
       "0       579     32.0      17.0      7       6  \n",
       "1      1535     56.0     273.0      4       1  \n",
       "2      1129     43.0      92.0     14      13  \n",
       "3      2582      6.0      26.0      2       1  \n",
       "4       684     11.0      67.0      9       6  \n",
       "...     ...      ...       ...    ...     ...  \n",
       "28312   400      NaN       NaN     53      32  \n",
       "28313   771      NaN       NaN     18      12  \n",
       "28314  1187      NaN       NaN      5       4  \n",
       "28315   945      NaN       NaN     83      63  \n",
       "28316  3403      NaN       NaN     85      25  \n",
       "\n",
       "[28317 rows x 8 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
